# V3 è®­ç»ƒè°ƒè¯•å¿«é€Ÿå‚è€ƒå¡

> **ç´§æ€¥æƒ…å†µ**: è®­ç»ƒå‡ºé—®é¢˜æ—¶å¿«é€ŸæŸ¥é˜…

---

## ğŸš¨ é—®é¢˜1: ä¸“å®¶å¡Œç¼©

### ç—‡çŠ¶
```
Alpha distribution: [0.95, 0.02, 0.02, 0.01]
Alpha entropy: 0.15
Expert usage: Survival=95%, Combat=2%, Exploration=2%, General=1%
```

### è¯Šæ–­
- Î±ç†µ < 0.3 âœ—
- æŸä¸ªä¸“å®¶ > 80% âœ—
- å…¶ä»–ä¸“å®¶æ¢¯åº¦æ¥è¿‘0 âœ—

### ç«‹å³è¡ŒåŠ¨
```python
# 1. å¢åŠ è´Ÿè½½å‡è¡¡ç³»æ•°
load_balance_coef = 0.05  # ä»0.01å¢åŠ åˆ°0.05

# 2. å»¶é•¿Warmup
warmup_episodes = 2000  # ä»1000å¢åŠ åˆ°2000

# 3. å¢åŠ Sparsemaxæ¸©åº¦
sparsemax_temp = 1.0  # ä»0.5å¢åŠ åˆ°1.0

# 4. å¼ºåˆ¶å‡åŒ€åˆå§‹åŒ–
def init_router_uniform(router):
    nn.init.constant_(router.router[-1].weight, 0)
    nn.init.constant_(router.router[-1].bias, 0)
```

### é¢„é˜²æªæ–½
- Warmupé˜¶æ®µä½¿ç”¨Softmax
- ç›‘æ§Î±ç†µï¼Œä½äº0.5æ—¶è­¦å‘Š
- å®šæœŸæ£€æŸ¥ä¸“å®¶ä½¿ç”¨ç‡

---

## ğŸš¨ é—®é¢˜2: GATè¿‡å¹³æ»‘

### ç—‡çŠ¶
```
GAT attention variance: 0.02
Operator activation rate: 3%
All node embeddings similar: cosine_sim > 0.95
```

### è¯Šæ–­
- æ³¨æ„åŠ›æ–¹å·® < 0.05 âœ—
- èŠ‚ç‚¹åµŒå…¥è¶‹åŒ âœ—
- Intent Vectorå˜åŒ–å° âœ—

### ç«‹å³è¡ŒåŠ¨
```python
# 1. å‡å°‘GATå±‚æ•°
num_gat_layers = 1  # ä»2å‡å°‘åˆ°1

# 2. å¢åŠ Dropout
gat_dropout = 0.3  # ä»0.1å¢åŠ åˆ°0.3

# 3. æ·»åŠ è¾¹Dropout
edge_dropout = 0.2

# 4. é™ä½å­¦ä¹ ç‡
learning_rate = 5e-5  # ä»1e-4é™ä½åˆ°5e-5
```

### é¢„é˜²æªæ–½
- é™åˆ¶GATå±‚æ•° â‰¤ 2
- ä½¿ç”¨æ®‹å·®è¿æ¥
- ç›‘æ§æ³¨æ„åŠ›æ–¹å·®

---

## ğŸš¨ é—®é¢˜3: æ¢¯åº¦çˆ†ç‚¸

### ç—‡çŠ¶
```
Gradient norm: 45.7
Loss: NaN
Parameters contain Inf
```

### è¯Šæ–­
- æ¢¯åº¦èŒƒæ•° > 10.0 âœ—
- æŸå¤±å˜ä¸ºNaN âœ—
- å‚æ•°çˆ†ç‚¸ âœ—

### ç«‹å³è¡ŒåŠ¨
```python
# 1. ç«‹å³å›æ»šåˆ°ä¸Šä¸€ä¸ªcheckpoint
policy_net.load_state_dict(last_good_checkpoint)

# 2. é™ä½å­¦ä¹ ç‡
learning_rate = 1e-5  # ä»1e-4é™ä½åˆ°1e-5

# 3. å¢åŠ æ¢¯åº¦è£å‰ª
max_grad_norm = 0.5  # ä»1.0é™ä½åˆ°0.5

# 4. æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
logits = torch.clamp(logits, -20, 20)
value = torch.clamp(value, -1000, 1000)
```

### é¢„é˜²æªæ–½
- æ¯æ¬¡æ›´æ–°å‰ä¿å­˜checkpoint
- å®æ—¶ç›‘æ§æ¢¯åº¦èŒƒæ•°
- ä½¿ç”¨LayerNorm

---

## ğŸš¨ é—®é¢˜4: å¥–åŠ±ä¸æ”¶æ•›

### ç—‡çŠ¶
```
Episode 5000: score=120
Episode 5100: score=115
Episode 5200: score=125
No improvement for 2000 episodes
```

### è¯Šæ–­
- Scoreé•¿æœŸéœ‡è¡ âœ—
- æ— æ˜æ˜¾ä¸Šå‡è¶‹åŠ¿ âœ—
- Î±æƒé‡æ··ä¹± âœ—

### ç«‹å³è¡ŒåŠ¨
```python
# 1. è°ƒæ•´å¥–åŠ±å¡‘å½¢
r_progress_weight = 0.5  # å¢åŠ è¿›å±•å¥–åŠ±æƒé‡
r_safety_weight = 0.3    # é™ä½å®‰å…¨æƒ©ç½š

# 2. å¢åŠ æ¢ç´¢
entropy_coef = 0.05  # ä»0.01å¢åŠ åˆ°0.05

# 3. æ£€æŸ¥ä»·å€¼ä¼°è®¡
# ä½¿ç”¨åŒCritic
critic1 = Critic(...)
critic2 = Critic(...)
value = torch.min(critic1(z), critic2(z))

# 4. å¢åŠ batch_size
batch_size = 512  # ä»256å¢åŠ åˆ°512
```

### é¢„é˜²æªæ–½
- å¥–åŠ±å½’ä¸€åŒ–
- ç›‘æ§ä»·å€¼ä¼°è®¡åå·®
- å®šæœŸè°ƒæ•´å¥–åŠ±æƒé‡

---

## ğŸš¨ é—®é¢˜5: NaN/Infå´©æºƒ

### ç—‡çŠ¶
```
RuntimeError: Function 'CategoricalBackward' returned nan values
Loss: tensor(nan)
Logits contain inf
```

### è¯Šæ–­
- å‰å‘ä¼ æ’­äº§ç”ŸNaN âœ—
- æŸå¤±è®¡ç®—å‡ºç°Inf âœ—
- æ¢¯åº¦åŒ…å«NaN âœ—

### ç«‹å³è¡ŒåŠ¨
```python
# 1. æ·»åŠ NaNæ£€æµ‹
def check_nan(tensor, name):
    if torch.isnan(tensor).any() or torch.isinf(tensor).any():
        print(f"âš ï¸ {name} contains NaN/Inf!")
        return True
    return False

# 2. åœ¨å…³é”®ä½ç½®æ£€æŸ¥
logits = policy_net(state)
if check_nan(logits, "logits"):
    # å›æ»šæˆ–è·³è¿‡
    continue

# 3. å¼ºåˆ¶æ•°å€¼ç¨³å®š
logits = torch.nan_to_num(logits, nan=0.0, posinf=20.0, neginf=-20.0)
logits = logits.clamp(-20.0, 20.0)

# 4. æ£€æŸ¥è¾“å…¥æ•°æ®
if check_nan(state, "state"):
    # æ•°æ®é—®é¢˜ï¼Œè·³è¿‡
    continue
```

### é¢„é˜²æªæ–½
- æ‰€æœ‰è¾“å‡ºåšnan_to_num
- æ‰€æœ‰logitsåšclamp
- å®ç°è‡ªåŠ¨å›æ»šæœºåˆ¶

---

## ğŸ“Š æ­£å¸¸è®­ç»ƒå‚è€ƒå€¼

```
Episode 1000:
  score: 100-150
  alpha_entropy: 1.0-1.2
  gradient_norm: 1.5-3.0
  expert_usage: [0.25, 0.25, 0.25, 0.25]

Episode 3000:
  score: 300-400
  alpha_entropy: 0.6-0.8
  gradient_norm: 1.0-2.5
  expert_usage: [0.20, 0.35, 0.30, 0.15]

Episode 5000:
  score: 500-700
  alpha_entropy: 0.5-0.7
  gradient_norm: 0.8-2.0
  expert_usage: [0.25, 0.30, 0.30, 0.15]
```

---

## ğŸ”§ ç´§æ€¥ä¿®å¤å‘½ä»¤

### é‡å¯è®­ç»ƒ (ä»checkpoint)
```bash
python ablation_v3/train/train_v3_gat_moe.py \
  --exp-name v3_full \
  --resume ablation_v3/results/v3_full/checkpoints/model_05000.pth \
  --learning-rate 5e-5
```

### é™çº§åˆ°Softmax
```bash
python ablation_v3/train/train_v3_gat_moe.py \
  --exp-name v3_softmax \
  --no-sparsemax
```

### å›ºå®šGAT
```bash
python ablation_v3/train/train_v3_gat_moe.py \
  --exp-name v3_fixed_gat \
  --freeze-gat
```

### å‡å°‘ä¸“å®¶
```bash
python ablation_v3/train/train_v3_gat_moe.py \
  --exp-name v3_2experts \
  --num-experts 2
```

---

## ğŸ“ è°ƒè¯•æ£€æŸ¥æ¸…å•

è®­ç»ƒå‡ºé—®é¢˜æ—¶ï¼ŒæŒ‰é¡ºåºæ£€æŸ¥ï¼š

- [ ] 1. æŸ¥çœ‹æœ€è¿‘50ä¸ªepisodesçš„æŒ‡æ ‡
- [ ] 2. æ£€æŸ¥Î±ç†µæ˜¯å¦æ­£å¸¸ (0.5-1.0)
- [ ] 3. æ£€æŸ¥æ¢¯åº¦èŒƒæ•°æ˜¯å¦æ­£å¸¸ (<5.0)
- [ ] 4. æ£€æŸ¥æ˜¯å¦æœ‰NaN/Inf
- [ ] 5. æŸ¥çœ‹ä¸“å®¶ä½¿ç”¨ç‡æ˜¯å¦å‡è¡¡
- [ ] 6. æ£€æŸ¥GATæ³¨æ„åŠ›æ–¹å·® (>0.1)
- [ ] 7. æŸ¥çœ‹å¥–åŠ±æ˜¯å¦å½’ä¸€åŒ–
- [ ] 8. æ£€æŸ¥å­¦ä¹ ç‡æ˜¯å¦åˆé€‚
- [ ] 9. æŸ¥çœ‹æ˜¯å¦åœ¨æ­£ç¡®çš„è®­ç»ƒé˜¶æ®µ
- [ ] 10. è€ƒè™‘æ˜¯å¦éœ€è¦é™çº§æ–¹æ¡ˆ

---

## ğŸ’¡ ç»éªŒæ³•åˆ™

1. **ä¸“å®¶å¡Œç¼©**: å¢åŠ è´Ÿè½½å‡è¡¡ï¼Œå»¶é•¿Warmup
2. **GATè¿‡å¹³æ»‘**: å‡å°‘å±‚æ•°ï¼Œå¢åŠ Dropout
3. **æ¢¯åº¦çˆ†ç‚¸**: é™ä½å­¦ä¹ ç‡ï¼Œå¢åŠ è£å‰ª
4. **å¥–åŠ±ä¸æ”¶æ•›**: è°ƒæ•´å¥–åŠ±å¡‘å½¢ï¼Œå¢åŠ æ¢ç´¢
5. **NaNå´©æºƒ**: æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§ï¼Œå®ç°å›æ»š

**è®°ä½**: ç¨³å®šæ€§ > æ€§èƒ½ã€‚å…ˆä¿è¯è®­ç»ƒä¸å´©æºƒï¼Œå†ä¼˜åŒ–æ€§èƒ½ã€‚

