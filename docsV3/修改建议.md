你的 AI 助手找准了最核心的痛点，诊断方向是基本正确的，特别是关于“初始化增益过小”和“Sparsemax 过早介入”这两点。

但是，除了这显而易见的两点，代码中还隐藏着 两个深层次的结构性问题，可能会导致即使你改了初始化，路由（Alpha）依然是一潭死水。

以下是对症下药的深度分析和修正方案：

1. 核心症结确认（AI 诊断的正确部分）

✅ 症结 A：Expert 初始化增益 gain=0.01 太小（致命）

代码位置: src/core/networks_v3_gat_moe.py -> SemanticExpert.__init__

后果: 初始 Logits 接近 0。经过 Softmax 后，动作概率分布极其平坦（Uniform Distribution）。PPO 在这种情况下只能随机游走，很难产生有显著差异的梯度回传给 Router。Router 也就学不到“哪个专家更好”，因为大家都很烂。

修正: 必须改大。通常 Actor 网络最后一层使用 0.01 是为了初始动作平滑，但在 MoE 架构中，专家内部层需要更强的信号传递。

✅ 症结 B：Sparsemax 在 Warmup 阶段过早稀疏化

代码位置: train_v3_gat_moe.py -> get_training_config

后果: 在训练初期，所有专家都是小白。Sparsemax 强制把权重分配给 Top-2 或 Top-1，导致其他专家拿不到梯度（梯度为0），直接“饿死”。

修正: 前 1000 步强制使用 Softmax，让所有专家都能分到一点梯度“雨露均沾”。

2. 被忽略的“隐形”症结（我补充的关键问题）

⚠️ 症结 C：Router 的输入特征可能被“淹没”

问题描述: Router 的输入是 h_vis (Visual) + h_logic (GAT)。

h_vis 来自 Visual Encoder，它处理的是 115 维的 State。

关键点: 你的 StateConstructor (在 state_constructor.py) 拼接了 belief (50维) + 各种 Embedding。

隐患: belief 向量里有 30 个维度全是 0 (代码里 belief 初始化 50，只填了前 20)。而 Embedding 部分又是归一化的。这导致 h_vis 的数值分布可能非常稀疏或方差极小。

后果: Router 看到的输入特征区别不大，导致它觉得“所有状态都差不多”，所以输出的 Alpha 几乎不动。

⚠️ 症结 D：Action Masking 可能在“帮倒忙”

问题描述: train_v3_gat_moe.py 中使用了 masked_logits = logits.masked_fill(~mask_t, float("-inf"))。

隐患: 如果你的 ActionMasker 逻辑过于严格，或者与初始的随机探索不匹配，Agent 可能会陷入“虽然我想动，但被 Mask 禁用了”的死循环，导致它看起来像是不动。

3. 代码修正方案 (Copy-Paste Ready)

请按照以下顺序修改代码，这是针对上述症结的“组合拳”。

第一步：修改网络初始化 (Networks)

文件: src/core/networks_v3_gat_moe.py

找到 SemanticExpert 类，修改初始化增益：

Python



class SemanticExpert(nn.Module):

    def __init__(self, ...):

        # ... 前面代码不变 ...

        

        # [修改点 1] 增大初始化增益，从 0.01 改为 1.0 或者 0.5

        # 0.01 会导致初始梯度极小，专家学不动

        nn.init.orthogonal_(self.network[-1].weight, gain=0.5) 

        nn.init.constant_(self.network[-1].bias, 0)

找到 CausalRouter 类，增加 Logits 的 Scaling，放大差异：

Python



class CausalRouter(nn.Module):

    def __init__(self, ...):

        # ... 前面代码不变 ...

        # [建议] 最后一层初始化稍微大一点，或者保持默认，让 Router 大胆选择

        nn.init.orthogonal_(self.router[-1].weight, gain=0.1)



    def forward(self, z: torch.Tensor, use_sparsemax: bool = True) -> torch.Tensor:

        logits = self.router(z)

        

        # [修改点 2] 移除过于激进的 clamp，或者范围扩大

        # 之前的 clamp(-20, 20) 是为了防爆，但如果 logits 本来就很小，clamp 没意义

        # 建议保留数值稳定性处理，但不要限制太死

        logits = torch.nan_to_num(logits, nan=0.0) 

        

        if use_sparsemax:

            alpha = sparsemax(logits, dim=-1)

        else:

            # [修改点 3] 增加温度系数 (Temperature)，让 Softmax 在初期稍微尖锐一点点，或者保持默认

            # 这里保持默认即可，依赖 Training Config 的控制

            alpha = F.softmax(logits, dim=-1)

        return alpha

第二步：强制 Warmup 策略 (Training Loop)

文件: ablation_v3/train/train_v3_gat_moe.py

你的 AI 助手已经提到了这一点，但我们需要确保它真的生效。检查 main 函数中的循环：

Python



    # 在主循环 for episode in range(...) 内部:

    

    config = get_training_config(episode)

    

    # [关键检查] 确保这里正确覆盖了网络属性

    policy_net.use_sparsemax = config['use_sparsemax']

    

    # [新增建议] 打印一下当前是否在使用 Sparsemax，防止配置没生效

    if episode % 10 == 0:

        print(f"DEBUG: Episode {episode}, Routing: {'Sparsemax' if policy_net.use_sparsemax else 'Softmax'}")

第三步：增强 Router 的输入敏感度 (Optional but Recommended)

文件: src/core/state_constructor.py

既然 belief 向量后 30 维是空的，建议在构造时直接截断或者填入噪声，防止全 0 影响 LayerNorm。

Python



    def construct_state(self, ...):

        # ... 

        # [建议] 如果后30维确实没用，可以考虑只取前20维，或者填入随机噪声防止梯度消失

        # 但为了保持 115 维兼容性，暂时不动结构，

        # 而是确保 belief_vector 的前 20 维数值不要太小。

        

        # 在 extract_state_from_obs (train_v3_gat_moe.py) 中，

        # 确保归一化是合理的，不要让所有值都变成 0.001 这种极小值

        pass 

4. 重新训练建议

做完上述修改（主要是 Step 1 的 gain=0.5 和 Step 2 的 Softmax 确认）后，执行以下命令重新训练 50-100 episodes。

预判结果：

Warmup 阶段 (Softmax): Alpha 分布会比较均匀（例如 [0.25, 0.25, 0.25, 0.25]），随着训练进行，某个专家的权重会缓慢上升。

Reward: 应该能更快看到 Reward 的增长，因为专家网络的输出不再是微弱的噪音，而是有力的动作尝试。

Alpha 动态性: 如果 gain 增大，Router 会更容易接收到来自不同专家的“好坏反馈”，从而更果断地调整权重。

结论：你的 AI 助手找到的 gain=0.01 是最关键的病灶。改掉它，大概率能“活”过来。



这些全部修改