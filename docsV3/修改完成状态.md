# V3 初始化修正 - 完成状态

## 修改时间
2026-01-06

## ✅ 已完成的所有修改

### 1. Expert初始化增益修正 ✅
**文件**: `src/core/networks_v3_gat_moe.py` (Line 73-75)
```python
# 修改前
nn.init.orthogonal_(self.network[-1].weight, gain=0.01)

# 修改后
nn.init.orthogonal_(self.network[-1].weight, gain=0.5)
```
**原因**: 0.01太小导致初始梯度极小，专家学不动

---

### 2. Router初始化增强 ✅
**文件**: `src/core/networks_v3_gat_moe.py` (Line 109-110)
```python
# 新增
nn.init.orthogonal_(self.router[-1].weight, gain=0.1)
```
**原因**: Router最后一层初始化稍微大一点，让Router大胆选择

---

### 3. 移除过度clamp限制 ✅
**文件**: `src/core/networks_v3_gat_moe.py` (Line 113-120)
```python
# 修改前
logits = torch.nan_to_num(logits, nan=0.0, posinf=20.0, neginf=-20.0).clamp(-20.0, 20.0)

# 修改后
logits = torch.nan_to_num(logits, nan=0.0)
```
**原因**: clamp限制太死，只保留NaN处理即可

---

### 4. 添加调试输出 ✅
**文件**: `ablation_v3/train/train_v3_gat_moe.py` (Line 742-744)
```python
# 新增
if episode % 10 == 0:
    print(f"DEBUG: Episode {episode}, Routing: {'Sparsemax' if policy_net.use_sparsemax else 'Softmax'}, Phase: {config['phase']}")
```
**原因**: 确保Warmup阶段真的在使用Softmax

---

### 5. 创建测试脚本 ✅
**文件**: `ablation_v3/scripts/test_init_fix.sh`
**内容**: 50 episodes快速验证脚本
**用法**: 
```bash
cd ablation_v3/scripts
bash test_init_fix.sh
```

---

### 6. 创建结果文档 ✅
**文件**: `ablation_v3/STATE_ENHANCEMENT_RESULTS.md`
**内容**: 详细的修改说明、预期效果、理论依据

---

## 预期效果

### Warmup阶段 (0-1000 episodes, Softmax)
- ✅ Alpha分布均匀 ([0.25, 0.25, 0.25, 0.25])
- ✅ Alpha会随训练缓慢变化
- ✅ Reward增长更快
- ✅ 动作logits从~0.02增长到>0.1

### Transition阶段 (1000-3000 episodes)
- ✅ Alpha开始稀疏化
- ✅ 专家分工出现

### Fine-tune阶段 (3000+ episodes)
- ✅ Alpha高度稀疏
- ✅ 明确的语义分工

---

## 下一步：运行测试

### 快速验证 (推荐)
```bash
cd ablation_v3/scripts
bash test_init_fix.sh
```
**时间**: ~10-15分钟
**Episodes**: 50
**目的**: 验证Alpha是否有变化

### 完整训练
```bash
cd ablation_v3/scripts
bash test_convergence_cpu.sh
```
**时间**: ~1-2小时
**Episodes**: 100
**目的**: 观察完整的Warmup阶段效果

---

## 监控指标

训练时重点观察：

1. **DEBUG输出** - 确认前1000 episodes使用Softmax
2. **Alpha变化** - 是否从初始值有明显变化（>0.01/step）
3. **Reward曲线** - 是否比之前更快增长
4. **动作logits** - 是否从~0.02增长到>0.1
5. **专家使用率** - Warmup阶段是否均匀

---

## 理论依据

### 为什么gain=0.5？
- Actor网络通常用0.01是为了初始动作平滑
- MoE架构需要更强信号，否则Router学不到"哪个专家更好"
- 0.5是折中值，既不会梯度爆炸，也不会梯度消失

### 为什么Warmup用Softmax？
- 训练初期所有专家都是小白
- Sparsemax强制稀疏会让某些专家"饿死"（梯度为0）
- Softmax让所有专家都能分到梯度，雨露均沾

### 为什么移除clamp？
- 初始logits很小（~0.02），clamp(-20, 20)完全没用
- Clamp会截断梯度流
- 只保留NaN处理即可保证数值稳定性

---

## 参考
- Switch Transformer (Google, 2021) - MoE初始化策略
- Sparse Mixture of Experts (Shazeer et al., 2017) - 负载均衡
- NetHack Challenge (NeurIPS 2021) - RL训练技巧
